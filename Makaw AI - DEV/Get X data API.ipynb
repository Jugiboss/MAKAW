{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c90573-85c0-4c73-9f1d-2305ab3da055",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Authenticate Azure Datalake and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22a8ddd8-4663-4e3e-ab7f-ac270022671f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, MapType\n",
    "\n",
    "# Azure Storage credentials\n",
    "storage_account_name = \"macavstorage\"\n",
    "container_name = \"datalake\"\n",
    "servicePrincipalID = \"0b27e0ea-e184-49cd-b921-b3519cb03f7f\"\n",
    "blobsecret = dbutils.secrets.get(scope=\"Scope1\", key=\"blobsecret1\")\n",
    "tenantID = \"60feac79-e042-4ce8-8759-dca313146110\"\n",
    "\n",
    "# Path to the file in Azure Data Lake\n",
    "# Create secret scope at \n",
    "# https://adb-4383697834848777.17.azuredatabricks.net/#secrets/createScope\n",
    "#Scope Name = Scope1\n",
    "#DNS Name = \"https://twitchkv.vault.azure.net/\" (Vault URI)\n",
    "#Resource ID = \"/subscriptions/972ad05f-b62e-48ab-a9fa-a17fd4dc6640/resourceGroups/twitchData/providers/Microsoft.KeyVault/vaults/twitchkv\" (Keyvault resource ID)\n",
    "\n",
    "#Initializing spark-session and adding configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DeltaLakeAzureStorage\") \\\n",
    "    .config(\"spark.sql.extensions\", \"delta.sql.DeltaSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Authenticating Serviceprincipal to access blob storage\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account_name}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account_name}.dfs.core.windows.net\", \n",
    "               \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account_name}.dfs.core.windows.net\", \n",
    "               servicePrincipalID)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account_name}.dfs.core.windows.net\", \n",
    "               blobsecret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account_name}.dfs.core.windows.net\", \n",
    "               f\"https://login.microsoftonline.com/{tenantID}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "19123867-7398-44bf-b4fe-e75f2faa0e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"x_data.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ðŸ”¥ Drop the old table (only if you want to reset!)\n",
    "cursor.execute(\"DROP TABLE IF EXISTS twitter_posts\")\n",
    "\n",
    "# âœ… Create table with correct schema\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE twitter_posts (\n",
    "    id TEXT PRIMARY KEY,\n",
    "    author_id TEXT,\n",
    "    username TEXT,\n",
    "    text TEXT,\n",
    "    created_at TEXT,\n",
    "    like_count INTEGER,\n",
    "    retweet_count INTEGER,\n",
    "    reply_count INTEGER,\n",
    "    quote_count INTEGER,\n",
    "    media_url TEXT,\n",
    "    source TEXT,\n",
    "    language TEXT,\n",
    "    api_completed_timestamp TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Commit and close the database connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eded60a9-59c8-4a1e-8603-9e8317b0bef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "# Set up Bearer Token (Replace with your actual token)\n",
    "\n",
    "BEARER_TOKEN = dbutils.secrets.get(scope=\"Scope1\", key=\"XBearerToken\")\n",
    "# Define the hashtag you want to search for (without #)\n",
    "HASHTAG = \"macavai\"\n",
    "\n",
    "# Twitter API endpoint for recent tweets with a hashtag\n",
    "url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "# Define query parameters\n",
    "params = {\n",
    "    \"query\": f\"#{HASHTAG} -is:reply\",  # Exclude replies\n",
    "    \"tweet.fields\": \"id,text,created_at,public_metrics,attachments,lang,source,author_id,entities\",\n",
    "    \"expansions\": \"attachments.media_keys,author_id\",\n",
    "    \"media.fields\": \"media_key,type,url\",\n",
    "    \"user.fields\": \"id,username\",\n",
    "    \"max_results\": 10,  # Adjust as needed (max 100)\n",
    "}\n",
    "\n",
    "# Set up headers with Bearer Token\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "}\n",
    "\n",
    "# Make API request\n",
    "response = requests.get(url, params=params, headers=headers)\n",
    "tweets_data = response.json()\n",
    "print(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abaa1d2e-8ada-426e-8f81-1901bc883536",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d77b5674-d648-48e8-a367-a7dc2c4ffea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tweets_data['data'][0]['entities']['hashtags'][1]['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d15ff680-0322-4446-8a27-3407a69ec501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract data\n",
    "tweet = tweets_data['data'][0]\n",
    "user = tweets_data['includes']['users'][0]\n",
    "\n",
    "tweet_id = tweet['id']\n",
    "text = tweet['text']\n",
    "hashtags = \",\".join([tag['tag'] for tag in tweet.get('entities', {}).get('hashtags', [])])\n",
    "author_id = tweet['author_id']\n",
    "username = user['username']\n",
    "created_at = tweet['created_at']\n",
    "\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5831dcba-fe15-44d4-86d4-4e85dd20bd0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "# Extract data\n",
    "tweet = tweets_data['data'][0]\n",
    "user = tweets_data['includes']['users'][0]\n",
    "\n",
    "tweet_id = tweet['id']\n",
    "text = tweet['text']\n",
    "hashtags = \",\".join([tag['tag'] for tag in tweet.get('entities', {}).get('hashtags', [])])\n",
    "author_id = tweet['author_id']\n",
    "geo = tweet.get(\"geo\", {}).get(\"place_id\", \"N/A\")\n",
    "username = user['username']\n",
    "created_at = tweet['created_at']\n",
    "\n",
    "# Public metrics\n",
    "metrics = tweet['public_metrics']\n",
    "retweet_count = metrics['retweet_count']\n",
    "reply_count = metrics['reply_count']\n",
    "like_count = metrics['like_count']\n",
    "quote_count = metrics['quote_count']\n",
    "bookmark_count = metrics['bookmark_count']\n",
    "impression_count = metrics['impression_count']\n",
    "\n",
    "# Get API completed timestamp (current time in UTC)\n",
    "#api_completed_timestamp = datetime.datetime.utcnow().isoformat()\n",
    "\n",
    "# Sample data\n",
    "tweet_data = {\n",
    "    \"id\": tweet_id,\n",
    "    \"text\": text,\n",
    "    \"hashtags\": hashtags,\n",
    "    \"author_id\": author_id,\n",
    "    \"username\": username,\n",
    "    \"created_at\": created_at,\n",
    "    \"retweet_count\": retweet_count,\n",
    "    \"reply_count\": reply_count,\n",
    "    \"like_count\": like_count,\n",
    "    \"quote_count\": quote_count,\n",
    "    \"bookmark_count\": bookmark_count,\n",
    "    \"impression_count\": impression_count,\n",
    "    \"geo_place_id\": geo,\n",
    "    \"api_completed_timestamp\": 0\n",
    "}\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "spark_df = spark.createDataFrame([Row(**tweet_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30483baa-a587-4821-8ad1-e1ef76f9bcc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Sample data from API\n",
    "\n",
    "# Extract data\n",
    "tweet = tweets_data['data'][0]\n",
    "user = tweets_data['includes']['users'][0]\n",
    "\n",
    "tweet_id = tweet['id']\n",
    "text = tweet['text']\n",
    "hashtags = \",\".join([tag['tag'] for tag in tweet.get('entities', {}).get('hashtags', [])])\n",
    "author_id = tweet['author_id']\n",
    "geo = tweet.get(\"geo\", {}).get(\"place_id\", \"N/A\")\n",
    "username = user['username']\n",
    "created_at = tweet['created_at']\n",
    "\n",
    "# Public metrics\n",
    "metrics = tweet['public_metrics']\n",
    "retweet_count = metrics['retweet_count']\n",
    "reply_count = metrics['reply_count']\n",
    "like_count = metrics['like_count']\n",
    "quote_count = metrics['quote_count']\n",
    "bookmark_count = metrics['bookmark_count']\n",
    "impression_count = metrics['impression_count']\n",
    "\n",
    "# Get API completed timestamp (current time in UTC)\n",
    "api_completed_timestamp = datetime.utcnow().isoformat()\n",
    "\n",
    "# Database connection\n",
    "conn = sqlite3.connect(\"x.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table with API completed timestamp\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS x_posts (\n",
    "    id TEXT PRIMARY KEY,\n",
    "    text TEXT,\n",
    "    hashtags TEXT,\n",
    "    author_id TEXT,\n",
    "    username TEXT,\n",
    "    created_at TEXT,\n",
    "    retweet_count INTEGER,\n",
    "    reply_count INTEGER,\n",
    "    like_count INTEGER,\n",
    "    quote_count INTEGER,\n",
    "    bookmark_count INTEGER,\n",
    "    impression_count INTEGER,\n",
    "    geo_place_id TEXT, \n",
    "    api_completed_timestamp TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Insert data\n",
    "cursor.execute(\"\"\"\n",
    "    INSERT OR REPLACE INTO x_posts (id, text, hashtags, author_id, username, created_at,\n",
    "                                   retweet_count, reply_count, like_count, quote_count,\n",
    "                                   bookmark_count, impression_count, geo_place_id, api_completed_timestamp)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\", (tweet_id, text, hashtags, author_id, username, created_at,\n",
    "      retweet_count, reply_count, like_count, quote_count, bookmark_count,\n",
    "      impression_count, geo, api_completed_timestamp))\n",
    "\n",
    "# Commit and close connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"Data inserted successfully with API timestamp:\", api_completed_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "931bddc1-8c93-471b-ba63-902f4e25de49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_name = \"x.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "\n",
    "# Read data into a Pandas DataFrame\n",
    "query = \"SELECT * FROM x_posts\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the first few rows\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af3590dc-0d65-45ab-ac7f-7bb7e608e6ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "974ea107-4a16-4752-83af-f66d574a910c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rate_limit_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "rate_limit_headers = {\n",
    "    \"Authorization\": f\"Bearer {BEARER_TOKEN}\"\n",
    "}\n",
    "response = requests.get(rate_limit_url, headers=rate_limit_headers)\n",
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "912bada8-2598-4ec7-a7fa-cd0e0bf613ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "reset_time = datetime.datetime.utcfromtimestamp(1742390900)\n",
    "print(\"Rate limit resets at:\", reset_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e50cb4c0-9d33-4b4a-8e9b-0be0d74c7134",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_rate_limit():\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "    headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    print(\"Remaining Requests:\", response.headers.get(\"x-rate-limit-remaining\"))\n",
    "    print(\"Rate Limit Resets At:\", response.headers.get(\"x-rate-limit-reset\"))  # UNIX timestamp\n",
    "\n",
    "check_rate_limit()\n",
    "reset_time = datetime.datetime.utcfromtimestamp(1742418326)\n",
    "print(reset_time)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Get X data API",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
